{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33a1cf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "22fa009d",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_text = '<p>HTML list come in two flavors: ordered and unordered. Ordered list tags automatically inserts the right numbers for each of the list items, where as the unordered list tag inserts bullets.</p> <ul> <li>First item in the list</li> <li>Second item in the list</li> <li>Third item in the list</li> </ul>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da0f6f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean=re.compile('<.*?>')\n",
    "cleantext=re.sub(clean, '', html_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53e12011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HTML list come in two flavors: ordered and unordered. Ordered list tags automatically inserts the right numbers for each of the list items, where as the unordered list tag inserts bullets.  First item in the list Second item in the list Third item in the list '"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleantext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d483b6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "68ad3bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_text = '<p>HTML list come in two flavors: ordered and unordered. Ordered list tags automatically inserts the right numbers for each of the list items, where as the unordered list tag inserts bullets.</p> <ul> <li>First item in the list</li> <li>Second item in the list</li> <li>Third item in the list</li> </ul>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8b38f8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleantext=BeautifulSoup(html_text, 'html.parser').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a8558cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HTML list come in two flavors: ordered and unordered. Ordered list tags automatically inserts the right numbers for each of the list items, where as the unordered list tag inserts bullets.  First item in the list Second item in the list Third item in the list '"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleantext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3088172b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2remove stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d41b58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bd403aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "55ccebde",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text = 'Machine Learning (ML) is the study of computer algorithms that improve automatically through experience.[1][2] It is seen as a subset of artificial intelligence. machine learning algorithms build a mathematical model based on sample data, known as \"training data\", in order to make predictions or decisions without being explicitly programmed to do so.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "71b3ca7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words=set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "449f88d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokens=word_tokenize(text)\n",
    "filtered_text=[word for word in word_tokens if word not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c376b30a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"MachineLearning(ML)studycomputeralgorithmsimproveautomaticallyexperience.[1][2]Itseensubsetartificialintelligence.machinelearningalgorithmsbuildmathematicalmodelbasedsampledata,known``trainingdata'',ordermakepredictionsdecisionswithoutexplicitlyprogrammed.\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(filtered_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5603e181",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3removing extra-spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f2ecff43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Machine learning (ML) is      the study of computer algorithms that improve automatically through experience.[1][2] It is seen as a subset of artificial intelligence. Machine learning algorithms build                a mathematical model based on sample data,      known as \"training data\", in order to make predictions or decisions without being      explicitly programmed to do so.'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Machine learning (ML) is      the study of computer algorithms that improve automatically through experience.[1][2] It is seen as a subset of artificial intelligence. Machine learning algorithms build                a mathematical model based on sample data,      known as \"training data\", in order to make predictions or decisions without being      explicitly programmed to do so.'\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b21afbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt=text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ff4001e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Machinelearning(ML)isthestudyofcomputeralgorithmsthatimproveautomaticallythroughexperience.[1][2]Itisseenasasubsetofartificialintelligence.Machinelearningalgorithmsbuildamathematicalmodelbasedonsampledata,knownas\"trainingdata\",inordertomakepredictionsordecisionswithoutbeingexplicitlyprogrammedtodoso.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "320fb365",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 converting number to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8d11181d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting num2words\n",
      "  Downloading num2words-0.5.10-py3-none-any.whl (101 kB)\n",
      "Collecting docopt>=0.6.2\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "Building wheels for collected packages: docopt\n",
      "  Building wheel for docopt (setup.py): started\n",
      "  Building wheel for docopt (setup.py): finished with status 'done'\n",
      "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13705 sha256=805306cf4b8491a42e9529270dc905049810adca9b92e6b595a6db7c4597a30f\n",
      "  Stored in directory: c:\\users\\my pc\\appdata\\local\\pip\\cache\\wheels\\56\\ea\\58\\ead137b087d9e326852a851351d1debf4ada529b6ac0ec4e8c\n",
      "Successfully built docopt\n",
      "Installing collected packages: docopt, num2words\n",
      "Successfully installed docopt-0.6.2 num2words-0.5.10\n"
     ]
    }
   ],
   "source": [
    "!pip install num2words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "790d35c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-lg==3.0.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.0.0/en_core_web_lg-3.0.0-py3-none-any.whl (778.8 MB)\n",
      "Requirement already satisfied: spacy<3.1.0,>=3.0.0 in c:\\users\\my pc\\anaconda3\\anaconda\\envs\\tensorflow\\lib\\site-packages (from en-core-web-lg==3.0.0) (3.0.6)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\my pc\\anaconda3\\anaconda\\envs\\tensorflow\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (2.0.5)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\my pc\\anaconda3\\anaconda\\envs\\tensorflow\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (0.7.4)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.3 in c:\\users\\my pc\\anaconda3\\anaconda\\envs\\tensorflow\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (2.0.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\my pc\\anaconda3\\anaconda\\envs\\tensorflow\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (52.0.0.post20210125)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\my pc\\anaconda3\\anaconda\\envs\\tensorflow\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (4.60.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\my pc\\anaconda3\\anaconda\\envs\\tensorflow\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (2.25.1)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in c:\\users\\my pc\\anaconda3\\anaconda\\envs\\tensorflow\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (0.3.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\my pc\\anaconda3\\anaconda\\envs\\tensorflow\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (2.4.1)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.3 in c:\\users\\my pc\\anaconda3\\anaconda\\envs\\tensorflow\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (8.0.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.4 in c:\\users\\my pc\\anaconda3\\anaconda\\envs\\tensorflow\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (3.0.5)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\my pc\\anaconda3\\anaconda\\envs\\tensorflow\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (0.5.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\my pc\\anaconda3\\anaconda\\envs\\tensorflow\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (1.20.1)\n",
      "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in c:\\users\\my pc\\anaconda3\\anaconda\\envs\\tensorflow\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (1.7.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\my pc\\anaconda3\\anaconda\\envs\\tensorflow\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (2.11.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\my pc\\anaconda3\\anaconda\\envs\\tensorflow\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (20.9)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\my pc\\anaconda3\\anaconda\\envs\\tensorflow\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (0.8.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\my pc\\anaconda3\\anaconda\\envs\\tensorflow\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (1.0.5)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\my pc\\anaconda3\\anaconda\\envs\\tensorflow\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (3.0.5)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\my pc\\anaconda3\\anaconda\\envs\\tensorflow\\lib\\site-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (2.4.7)\n",
      "Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in c:\\users\\my pc\\anaconda3\\anaconda\\envs\\tensorflow\\lib\\site-packages (from pathy>=0.3.5->spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (3.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\my pc\\anaconda3\\anaconda\\envs\\tensorflow\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\my pc\\anaconda3\\anaconda\\envs\\tensorflow\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\my pc\\anaconda3\\anaconda\\envs\\tensorflow\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\my pc\\anaconda3\\anaconda\\envs\\tensorflow\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (1.26.4)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in c:\\users\\my pc\\anaconda3\\anaconda\\envs\\tensorflow\\lib\\site-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\my pc\\anaconda3\\anaconda\\envs\\tensorflow\\lib\\site-packages (from jinja2->spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (1.1.1)\n",
      "Installing collected packages: en-core-web-lg\n",
      "Successfully installed en-core-web-lg-3.0.0\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_lg')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_lg \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f453c70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_lg \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35b0bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm\n",
    "\n",
    "nlp = en_core_web_sm.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcab9eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from num2words import num2words as n2w\n",
    "import spacy\n",
    "nlp=spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0dbf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711d5ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'I will be there by 3. Its 5 am now. Can the meeting be shifted to 7.'\n",
    "\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46faf5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19baa90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b57a093",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)\n",
    "tokens = [n2w(token.text) if token.pos_ == 'NUM' else token.text for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1492c96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b0995c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Machine Learning (ML) is the study of computer algorithms that improve automatically through experience.[1][2] It is seen as a subset of artificial intelligence. machine learning algorithms build a mathematical model based on sample data, known as \"training data\", in order to make predictions or decisions without being explicitly programmed to do so.'\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb336d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f81a6218",
   "metadata": {},
   "outputs": [],
   "source": [
    "lowered_text=text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7cb9cb67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'machine learning (ml) is the study of computer algorithms that improve automatically through experience.[1][2] it is seen as a subset of artificial intelligence. machine learning algorithms build a mathematical model based on sample data, known as \"training data\", in order to make predictions or decisions without being explicitly programmed to do so.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lowered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "51fc3fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#t0kenizarions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aa90901a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import  word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f65a91cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Machine Learning (ML) is the study of computer algorithms that improve automatically through experience.[1][2] It is seen as a subset of artificial intelligence. machine learning algorithms build a mathematical model based on sample data, known as \"training data\", in order to make predictions or decisions without being explicitly programmed to do so.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Machine Learning (ML) is the study of computer algorithms that improve automatically through experience.[1][2] It is seen as a subset of artificial intelligence. machine learning algorithms build a mathematical model based on sample data, known as \"training data\", in order to make predictions or decisions without being explicitly programmed to do so.'\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "872d8a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokens=word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "56ccd7b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Machine',\n",
       " 'Learning',\n",
       " '(',\n",
       " 'ML',\n",
       " ')',\n",
       " 'is',\n",
       " 'the',\n",
       " 'study',\n",
       " 'of',\n",
       " 'computer',\n",
       " 'algorithms',\n",
       " 'that',\n",
       " 'improve',\n",
       " 'automatically',\n",
       " 'through',\n",
       " 'experience',\n",
       " '.',\n",
       " '[',\n",
       " '1',\n",
       " ']',\n",
       " '[',\n",
       " '2',\n",
       " ']',\n",
       " 'It',\n",
       " 'is',\n",
       " 'seen',\n",
       " 'as',\n",
       " 'a',\n",
       " 'subset',\n",
       " 'of',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " '.',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'algorithms',\n",
       " 'build',\n",
       " 'a',\n",
       " 'mathematical',\n",
       " 'model',\n",
       " 'based',\n",
       " 'on',\n",
       " 'sample',\n",
       " 'data',\n",
       " ',',\n",
       " 'known',\n",
       " 'as',\n",
       " '``',\n",
       " 'training',\n",
       " 'data',\n",
       " \"''\",\n",
       " ',',\n",
       " 'in',\n",
       " 'order',\n",
       " 'to',\n",
       " 'make',\n",
       " 'predictions',\n",
       " 'or',\n",
       " 'decisions',\n",
       " 'without',\n",
       " 'being',\n",
       " 'explicitly',\n",
       " 'programmed',\n",
       " 'to',\n",
       " 'do',\n",
       " 'so',\n",
       " '.']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "70f64ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "014ca048",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a92c6174",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "75e0051f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d8dea10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "words=['siting', 'thinking', 'going', 'walking', 'drinking']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d203c45d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "siting  site\n",
      "thinking  think\n",
      "going  go\n",
      "walking  walk\n",
      "drinking  drink\n"
     ]
    }
   ],
   "source": [
    "for w in words:\n",
    "    print(w, \"\", ps.stem(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4813e195",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2f6c253f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3e72aa9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5b5aec7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rocks rock\n"
     ]
    }
   ],
   "source": [
    "print('rocks', lemmatizer.lemmatize('rocks'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "24e7ed40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eatings eat\n"
     ]
    }
   ],
   "source": [
    "print('eatings', lemmatizer.lemmatize('eating', pos='v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6267b94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spell checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c2b7fd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b76646c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Using cached textblob-0.15.3-py2.py3-none-any.whl (636 kB)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\my pc\\anaconda3\\anaconda\\envs\\tensorflow\\lib\\site-packages (from textblob) (3.6.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\my pc\\anaconda3\\anaconda\\envs\\tensorflow\\lib\\site-packages (from nltk>=3.1->textblob) (4.60.0)\n",
      "Requirement already satisfied: click in c:\\users\\my pc\\anaconda3\\anaconda\\envs\\tensorflow\\lib\\site-packages (from nltk>=3.1->textblob) (7.1.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\my pc\\anaconda3\\anaconda\\envs\\tensorflow\\lib\\site-packages (from nltk>=3.1->textblob) (1.0.1)\n",
      "Requirement already satisfied: regex in c:\\users\\my pc\\anaconda3\\anaconda\\envs\\tensorflow\\lib\\site-packages (from nltk>=3.1->textblob) (2021.4.4)\n",
      "Installing collected packages: textblob\n",
      "Successfully installed textblob-0.15.3\n"
     ]
    }
   ],
   "source": [
    "! pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6096c98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4302500b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'I am ging there. Will brng the thngs from tem'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "785d1be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens=word_tokenize(text)\n",
    "res=[]\n",
    "for token in tokens:\n",
    "    word=TextBlob(token)\n",
    "    res.append(str(word.correct()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "abb12bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am going there . Will bring the things from them'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa3047a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
